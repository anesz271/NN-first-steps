{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "numbers_im_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNzj7E54r7Leoumr79yBHdS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anesz271/NN-first-steps/blob/main/numbers_im_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2VCZkRjlnN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf83469-bd46-4049-e2d4-afe766e17349"
      },
      "source": [
        "# import data and libraries\r\n",
        "import tensorflow as tf\r\n",
        "data = tf.keras.datasets.mnist\r\n",
        "(training_images, training_labels), (val_images, val_labels) = data.load_data()\r\n",
        "\r\n",
        "# normalizing pixel values (originally each pixel values is 0-255)\r\n",
        "training_images  = training_images / 255.0\r\n",
        "val_images = val_images / 255.0\r\n",
        "\r\n",
        "# define the NN \r\n",
        "# first flatten the 28*28 dim pictures\r\n",
        "# 20 neurons in the first layer\r\n",
        "# 10 neurons in the second because there are 10 possible outputs\r\n",
        "layer_1 = tf.keras.layers.Dense(20, activation=tf.nn.relu)\r\n",
        "layer_2 = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\r\n",
        "                                    layer_1,\r\n",
        "                                    layer_2])\r\n",
        "\r\n",
        "# adam can vary its learning rate to converge more quickly\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss='sparse_categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "# the training loop\r\n",
        "model.fit(training_images, training_labels, epochs=20, validation_data=(val_images, val_labels))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6827 - accuracy: 0.8096 - val_loss: 0.2543 - val_accuracy: 0.9253\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2370 - accuracy: 0.9321 - val_loss: 0.2061 - val_accuracy: 0.9388\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1990 - accuracy: 0.9436 - val_loss: 0.1936 - val_accuracy: 0.9434\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1752 - accuracy: 0.9485 - val_loss: 0.1734 - val_accuracy: 0.9482\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1601 - accuracy: 0.9532 - val_loss: 0.1664 - val_accuracy: 0.9513\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1506 - accuracy: 0.9563 - val_loss: 0.1643 - val_accuracy: 0.9510\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1424 - accuracy: 0.9591 - val_loss: 0.1637 - val_accuracy: 0.9518\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1341 - accuracy: 0.9602 - val_loss: 0.1610 - val_accuracy: 0.9526\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1303 - accuracy: 0.9609 - val_loss: 0.1585 - val_accuracy: 0.9553\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1230 - accuracy: 0.9635 - val_loss: 0.1534 - val_accuracy: 0.9545\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1231 - accuracy: 0.9638 - val_loss: 0.1549 - val_accuracy: 0.9556\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1106 - accuracy: 0.9677 - val_loss: 0.1552 - val_accuracy: 0.9550\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1079 - accuracy: 0.9684 - val_loss: 0.1510 - val_accuracy: 0.9574\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1072 - accuracy: 0.9675 - val_loss: 0.1558 - val_accuracy: 0.9555\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1051 - accuracy: 0.9690 - val_loss: 0.1504 - val_accuracy: 0.9576\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1026 - accuracy: 0.9690 - val_loss: 0.1514 - val_accuracy: 0.9588\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0957 - accuracy: 0.9714 - val_loss: 0.1546 - val_accuracy: 0.9567\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0941 - accuracy: 0.9721 - val_loss: 0.1506 - val_accuracy: 0.9566\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0913 - accuracy: 0.9726 - val_loss: 0.1602 - val_accuracy: 0.9536\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0864 - accuracy: 0.9745 - val_loss: 0.1568 - val_accuracy: 0.9571\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fee03eae1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELCuSnNsloVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c3d6eff-5dd2-4734-c87c-34b4a54f8c35"
      },
      "source": [
        "# printing the result for the first image (expected output: 7)\r\n",
        "\r\n",
        "# get metrics for a test set\r\n",
        "model.evaluate(val_images, val_labels)\r\n",
        "\r\n",
        "classifications = model.predict(val_images)\r\n",
        "print(classifications[0])\r\n",
        "print(val_labels[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0704927e-06 2.0301558e-12 1.0141279e-05 2.3955684e-03 8.1657310e-13\n",
            " 6.2200250e-08 1.0348561e-14 9.9759018e-01 4.0871689e-07 2.6156597e-06]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDyxMtEFqHUQ",
        "outputId": "c90b4a95-01d6-4645-cc28-0740a3cb7e29"
      },
      "source": [
        "# inspect weights\r\n",
        "# 20 neurons in this layer\r\n",
        "# every image is 28*28 pixel\r\n",
        "# 28*28*20 = 15680\r\n",
        "# each neuron learns a w parameter for each pixel\r\n",
        "# every pixel has a weight in every neuron. those weights are multiplied by the pixel value, summed up, and given a bias \r\n",
        "print(layer_1.get_weights()[0].size)\r\n",
        "# the biases for each neuron in this layer\r\n",
        "print(layer_1.get_weights()[1].size)\r\n",
        "\r\n",
        "# same for layer_2\r\n",
        "# 20 incoming weights * 10 neurons in this layer\r\n",
        "print(layer_2.get_weights()[0].size)\r\n",
        "# the biases for each neuron in this layer\r\n",
        "print(layer_2.get_weights()[1].size)\r\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15680\n",
            "20\n",
            "200\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}